---
title: "R Notebook"
output: html_notebook
---

```{r message=FALSE}
library(Seurat)
library(dplyr)
library(tidyverse)
#library(Matrix)
#library(spatstat)
library(patchwork)
library(cellranger)
library(ggplot2)
#library(SCINA)
#library(plot3D)
#library(plotly)
# BiocManager::install("rhdf5")
# install.packages("SeuratDisk")
# remotes::install_github("mojaveazure/seurat-disk") # When running this you need to let it update hdf5r 
library(SeuratDisk)
library(hdf5r)
library(SeuratWrappers)
library(reticulate) #Important for running python on rstudio

Sys.which("python")
Sys.setenv(RETICULATE_PYTHON = Sys.which("python")) # This links the reticulate to your terminal python
```
```{r} 
# Very optional. This code is meant to use multiple cores at once to make things faster, but rstudio is apparently a bit crashy with it. I used it only for the normalized data bit because that didn't seem to cause crashes and turned it from 2min to 30s
#library(future) 
#options(future.globals.maxSize = 1000 * 1024^2)
```


Note:
- This is just a consolidation of other guides/code. Links to them are provided in the code.
- The velocyto and scVelo parts of the code are run via python. This is done in rstudio via the package reticulate. For this to work you need to have a terminal running python that has installed the relevant packages(in this case "import scvelo as scv") in parallel with the opened rstudio
- The modules you need to load from the cluster are; R, rstudio, python, samtools(for scvelo), hdf5(for the SeuratDisk/Wrappers package), velocyto
- Consolidated by Sebastian Ljung(sl2014@cam.ac.uk), intern under Jasmin Stowers(Jasmin.Stowers@babraham.ac.uk)

STEP 0:
- Installings SeuratWrappers was a bit confusing, I think you need to install seurat disk via github(see above) and it will request to update hdf5r(which might or might not be different from rhdf5). Ask Jasmin if things don't work out.

- Open 2 terminals, in both load the modules R, rstudio, python, hdf5, velocyto, samtools
  - One is for rstudio where you now write "rstudio" in the terminal
  - The other is for python where you first write "python", then in python "import scvelo as scv"
    - Scvelo has already been installed for python in the cluster





STEP 1: Generating loom file
- velocyto takes 10x data and differentiated between spliced, unspliced and ambiguous genes to create a loom file that will be used for scVelo
- This can either be run on your terminal or via R using the "system()" function
- Based on this guide: https://velocyto.org/velocyto.py/tutorial/cli.html


Requirements:
- On the cluster; 
  - module load R
  - module load rstudio
  - module load velocyto (might only be necessary for velocyto processing)
  - module load hdf5 (needed for several steps)
  - module load samtools (might only be needed for velocyto processing)
  - module load python Doesn't require python yet, can be run on cluster terminal, but worth loading after velocyto
  
- File format;
  - When running the code you want to direct velocyto to the folder containing the "outs" folder;
  
  - outs/filtered_feature_bc_matrix/
    - Which contains: barcodes.tsv.gz, features.tsv.gz, matrix.mtx.gz (don't have to be unziped from my experience so far)
  - outs/
    - Which in my case contained: analysis, molecule_info.h5, cellsorted_possorted_genome_bam.bam, possorted_genome_bam.bam,      cloupe.cloupe, possorted_genome_nam.bam.bai, filtered_feature_bc_matrix, raw_feature_bc_matric, filtered_feature_bc_matrix.h5,    raw_feature_bc_matrix.h5, metrics_summary.csv_web_summary.html
    - I don't know which of these are essential but I think the bam files, molecule, and possorted genome files are important
  - You also need the genes.gtf file which you can get from the bi cluster
    - /bi/scratch/Genomes/10x/human/refdata-cellranger-GRCh38-1.2.0/genes/genes.gtf
    
    Note:
    - If your files have slightly different names you might have to rename them
    - Your bam data from sequencing may be hidden inside a tar file, usually unziping them will create a folder with everything in the right           place
    - If you velocyto gave back a "truncated" error of sorts add "-t uint32" after the "run10x" part
    - If your velocyto didn't work try deleting the cellsorted file and any temporary cellsorted files
  
    
Output:
- Creates a folder called velocyto in the same folder where you find your outs folder. This should contain the .loom file
  
 
```{r}
### --- Generating loom file through cluster/linux operating system/console, can be run in here too

# system("velocyto run10x /bi/home/ljungs/velocyto_prgm/SIGAA8/SIGAA8_h0 /bi/scratch/Genomes/10x/human/refdata-cellranger-GRCh38-1.2.0/genes/genes.gtf")

```

STEP 2: Seurat Clustering
- This bit is run through normal R and creates the standard clustering that will be used as a framework by scVelo
- It is based on Jasmin's Seurat code, guide to Seurat can be found here: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html

Requirements:
- .loom file
- module load R
- module load rstudio
- module load hdf5 (needed for several steps)
- module load velocyto (might only be necessary for velocyto processing)


- To ensure that your seurat clustering and scvelo clustering agree it is recommended that you run the .loom file through Seurat and then extract it as a hdf5 file for Seurat processing
- The .loom file is converted to a Seurat object by;
  - ldat <- ReadVelocity(file = "/bi/home/ljungs/velocyto_prgm/SIGAA8/SIGAA8_h0/velocyto/SIGAA8_h0.loom")
  - h0 <- as.Seurat(x = ldat) (I haven't figured out how to add the usual min.cells and min.features without getting errors, but should be       possible)
  
- Once the seurat processing is over it is converted to an hdf5/anndata file(useful in python) via the SaveH5Seurat and Convert functions
  

```{r}
##### ---- LOAD DATA ---- #####

setwd("/bi/home/ljungs/")

##### ---- h0 + FILTER ---- #####

ldat <- ReadVelocity(file = "/bi/home/ljungs/HNES.loom")
h0 <- as.Seurat(x = ldat)

# h0 <- hh0

h0[["percent.mt"]] <- PercentageFeatureSet(h0, pattern = "^MT-")
h0$percent.largest.gene <- apply(h0@assays$spliced@counts, 2, function(x)(100*max(x))/sum(x))

VlnPlot(h0, features = c("nFeature_spliced", "nCount_spliced", "percent.mt","percent.largest.gene"),ncol = 4)

h0 <- subset(h0, subset = nFeature_spliced > 2000 & nFeature_spliced < 150000 & percent.mt < 15 & percent.largest.gene < 20)

VlnPlot(h0, features = c("nFeature_spliced", "nCount_spliced", "percent.mt","percent.largest.gene"), ncol = 4)

```

```{r}

##### ----  CLR-NORMALIZE ---- #### /.../
#plan("multiprocess", workers = 4) # Optional bit, workers=cpu cores used. Requires future library
h0 <- NormalizeData(h0, normalization.method = "CLR")
#plan("sequential") # This bit turns it off after normalization

######## seeing how normalization looks #########
# ggplot(mapping = aes(h0@assays$RNA@data["GAPDH",])) +
#   geom_histogram(binwidth = 0.05, fill="yellow", colour="black") +
#   ggtitle("GAPDH CLR")
# as.tibble(h0@assays$RNA@data[,1:100]) %>%
#   pivot_longer(cols=everything(),names_to="cell", values_to="expression") %>%
#   ggplot(aes(x=expression, group=cell)) +
#   geom_density() +
#   coord_cartesian(ylim=c(0,0.6), xlim=c(0,3))

```

```{r message=FALSE}
# k <- sample(1:20,1)
# set.seed(k)

##### ----  HIGHLY VARIABLE FEATURES ---- ####
h0 <- FindVariableFeatures(h0, selection.method = "vst", nfeatures = 400)

##### ----  SCALING ---- ####
all.genes <- rownames(h0)
h0 <- ScaleData(h0, features = all.genes)
rm(all.genes)

### ---- PCA ---- ##
h0 <- RunPCA(h0, features = VariableFeatures(object = h0))

### ---- TSNE ---- ##
#h0 <- RunTSNE(h0, dims = 1:30, seed.use=k, perplexity= 30)
```

```{r,fig.height=4, fig.width=8}

##### ---- CLUSTER CELLS ---- ####

h0 <- FindNeighbors(h0, dims = 1:30)
h0 <- FindClusters(h0, resolution = 1.8)

##### ---- NON-LIN DEM REDUCTION UMAP  ---- ####

h0 <- RunUMAP(h0, dims = 1:30, n.components = 2L, n.neighbors = 40L)
DimPlot(h0, reduction = "umap", group.by ="seurat_clusters")
```
  
```{r}
# Reformating Seurat file so it can be saved as anndata file with spliced data as it's counts and spliced, unspliced, ambiguous as layers
# Both spliced and unspliced are required as layers in scvelo, the function otherwise converts spliced into counts without a spliced layer

h01 <- h0
h01[["X"]] <- h0[["spliced"]]
h01[["spliced"]] <- h0[["spliced"]]
h01[["ambiguous"]] <- h0[["ambiguous"]]
h01[["unspliced"]] <- h0[["unspliced"]]
DefaultAssay(object = h01) <- "X"

SaveH5Seurat(h01, filename = "h01.h5Seurat", overwrite = TRUE)
Convert("h01.h5Seurat", dest = "h5ad", overwrite = TRUE)
```


STEP 3: Analysing clusters and data using scVelo
- Runs the python scVelo code for analysing the h5ad file generated in seurat to derive a estimate trajectory based on spliced vs unspliced RNA for each cell
- Based on these guides; 
- https://scvelo.readthedocs.io/getting_started/
- http://htmlpreview.github.io/?https://github.com/satijalab/seurat-wrappers/blob/master/docs/scvelo.html
- The first link provides a thurough guide and explaination to how the code is processed
- If you get an error can't find scv then try running the import line in rstudio again

- Here is where the python terminal with all the modules and running "import scvelo as scv" is necessary

Requirements:
- .h5ad file
- module load R
- module load rstudio
- module load python
- module load hdf5 (needed for several steps)
- module load velocyto (might only be necessary for velocyto processing)


```{r}
# Incase you/I forgot to setup the python terminal, run this after doing so
Sys.setenv(RETICULATE_PYTHON = Sys.which("python")) 
```

```{python}
# Loads the data, processes it for scvelo and provides the standard trajectory plot

import scvelo as scv
import scanpy as sc # Not necessary but useful for extra things
import numpy as np # Not necessary but useful for extra things
#scv.settings.verbosity = 3  # show errors(0), warnings(1), info(2), hints(3)
#scv.settings.presenter_view = True  # set max width size for presenter view
#scv.settings.set_figure_params('scvelo') # for beautified visualization

#Loading data
adata = scv.read("/bi/home/ljungs/h09.h5ad")
adata
adata.X #peak into what the dataframe looks like


#scv.pp.filter_and_normalize(adata, enforce = True) # Had issues with this due to negatives and zeros from earlier normalizing, can be skipped as data has already been filtered and normalized

scv.pp.moments(adata, n_pcs=30, n_neighbors=30) #Necessary
```

```{python}
# Proportions of spliced to unspliced

# Normally worked but on some occasions didn't(nuclear RNA-seq seemed to cause issues)
lay = np.array(["spliced", "unspliced"])
scv.pl.proportions(adata, layers = ["spliced", "unspliced"], groupby= "clusters") 
```

```{python}
# Deriving stocastic velocity, makes some assumptions on things like splicing rate. Run either this or the dynamic
scv.tl.velocity(adata)
scv.tl.velocity_graph(adata)
```

```{python}
# Deriving dynamic velocity, uses math magic to make more complex estimates and fewer assumptions of variables. Run either this or the stocastic

scv.tl.recover_dynamics(adata)
scv.tl.velocity(adata, mode='dynamical')
scv.tl.velocity_graph(adata)

adata.write('/bi/home/ljungs/Saves/h014D.h5ad') # Dynamic analysis takes a bit longer, hence saving might be worth it
```
```{python}
adata = scv.read('/bi/home/ljungs/Saves/h014D.h5ad') # Load saved dynamic analysis
```

```{python} 
# Generate the standard velocity trajectory plot
scv.pl.velocity_embedding_stream(adata, basis="umap", color="seurat_clusters", size = 40, alpha = 1, density = 2, figsize= (12,10))
```

```{python}
# Similar to trajectory plot but individual cells represented as spearheads 
scv.pl.velocity_embedding(adata, basis="umap", color="seurat_clusters", arrow_length=5, arrow_size=2.5, dpi=240, figsize= (12,10))
```

```{python}
# Estimates a pseudotime gradient 
scv.tl.recover_dynamics(adata)
scv.tl.latent_time(adata)
scv.pl.scatter(adata, color="latent_time", color_map="gnuplot", figsize= (12,10))
```

```{python}
# Provides a heatmap to identify variable genes for each cluster
top_genes = adata.var["fit_likelihood"].sort_values(ascending=False).index[:30]
scv.pl.heatmap(adata, var_names=top_genes, sortby="latent_time", col_color="seurat_clusters", n_convolve=30,figsize=(20,10))
```

```{python}
# Second important bit, generates velocity plots of individual genes and plots their velocity and expression on umap
scv.pl.velocity(adata, ["genes of interest"], ncols=1, figsize= (20,10), dpi=400, fontsize= 30)
```


```{python}
# Estimates gene drivers for velocity in each clusters
scv.tl.rank_velocity_genes(adata, groupby='seurat_clusters', min_corr=.1)
df = scv.DataFrame(adata.uns['rank_velocity_genes']['names'])
df.head(200)
```

```{python}
# Creates velocity plots for the top gene drivers in a given cluster
scv.pl.scatter(adata, df['cluster'][:10], fontsize=20)
```

```{python}
# Shows magnitude of velocities on umap and predicts confidence of trajectory based on how well neighboring trajectories align
scv.tl.velocity_confidence(adata)
keys = 'velocity_length', 'velocity_confidence'
scv.pl.scatter(adata, c=keys, cmap='coolwarm', perc=[5, 95],figsize= (16,7))
```

```{python}
# Predicts future trajectory of a cell based on other cells, haven't figured out how to find what cell has what number
#scv.pl.velocity_graph(adata, threshold=.1)
x, y = scv.utils.get_cell_transitions(adata, basis='umap', starting_cell=38)
ax = scv.pl.velocity_graph(adata, c='lightgrey', edge_width=.05, show=False)
ax = scv.pl.scatter(adata, x=x, y=y, s=120, c='ascending', cmap='gnuplot', ax=ax)
```

```{python}
# Estimates relative pseudotime between cells
scv.tl.velocity_pseudotime(adata)
scv.pl.scatter(adata, color='velocity_pseudotime', cmap='gnuplot',figsize= (12,10))
```

```{python}
# If velocities cycle based on cell cycle this plot predicts what stage in the cell cycle clusters/cells are
scv.tl.score_genes_cell_cycle(adata)
scv.pl.scatter(adata, color_gradients=['S_score', 'G2M_score'], smooth=True, perc=[5, 95])
```

STOP HERE, UNDER CONSTRUCTION?!?!
- So far the stuff below hasn't been tested and may in some cases be repreats of analysis done above, for further analysis refer to https://scvelo.readthedocs.io/getting_started/

```{python}
# Calculating kinetic rate parameters
# Estimates rates of RNA transcription, splicing and degredation
df = adata.var
df = df[(df['fit_likelihood'] > .1) & df['velocity_genes'] == True]

kwargs = dict(xscale='log', fontsize=16)
with scv.GridSpec(ncols=3) as pl:
    pl.hist(df['fit_alpha'], xlabel='transcription rate', **kwargs)
    pl.hist(df['fit_beta'] * df['fit_scaling'], xlabel='splicing rate', xticks=[.1, .4, 1], **kwargs)
    pl.hist(df['fit_gamma'], xlabel='degradation rate', xticks=[.1, .4, 1], **kwargs)

scv.get_df(adata, 'fit*', dropna=True).head()
```

```{python}
# Estimates driver genes, not cluster specific, that produce dynamic behaviour
top_genes = adata.var['fit_likelihood'].sort_values(ascending=False).index
scv.pl.scatter(adata, basis=top_genes[:15], ncols=5, frameon=False)

# Allows you to look at the dynamics of genes of interest
var_names = ['Actn4', 'Ppp3ca', 'Cpe', 'Nnat']
scv.pl.scatter(adata, var_names, frameon=False)
scv.pl.scatter(adata, x='latent_time', y=var_names, frameon=False)
```

```{python}
# Cluster specific driver genes
scv.tl.rank_dynamical_genes(adata, groupby='clusters')
df = scv.get_df(adata, 'rank_dynamical_genes/names')
df.head(5)
adata
# Allows you to specify clusters
for cluster in ['1', '6',]:
    scv.pl.scatter(adata, df[cluster][:5], ylabel=cluster, frameon=False)
```

Differential Kinetic Test
- Takes into account differential/alternative splicing, polyadenylation and degradation mechanics for different cell types and lineages
- Creates a liklihood ratio following a asymptotic chi-squared distribution
- This can then be used to create a new, hopefully more accurate, velocity plot

```{python}

var_names = ['Tmsb10', 'Fam155a', 'Hn1', 'Rpl6']
scv.tl.differential_kinetic_test(adata, var_names=var_names, groupby='clusters')

scv.get_df(adata[:, var_names], ['fit_diff_kinetics', 'fit_pval_kinetics'], precision=2)
```

```{python}

kwargs = dict(linewidth=2, add_linfit=True, frameon=False)
scv.pl.scatter(adata, basis=var_names, add_outline='fit_diff_kinetics', **kwargs)
```

```{python}
# Seems to add an outline differentiating clusters with observed differing kinetics
diff_clusters=list(adata[:, var_names].var['fit_diff_kinetics'])
scv.pl.scatter(adata, legend_loc='right', size=60, title='diff kinetics',add_outline=diff_clusters, outline_width=(.8, .2))
```

```{python}
# Recomputes gene driver dynamics but now accounting for the differential kinetics
scv.tl.recover_dynamics(adata)

top_genes = adata.var['fit_likelihood'].sort_values(ascending=False).index[:100]
scv.tl.differential_kinetic_test(adata, var_names=top_genes, groupby='clusters')

scv.pl.scatter(adata, basis=top_genes[:15], ncols=5, add_outline='fit_diff_kinetics', **kwargs)
scv.pl.scatter(adata, basis=top_genes[15:30], ncols=5, add_outline='fit_diff_kinetics', **kwargs)
```

Recomputing velocities
- Creates a new velocity plot accounting for the differential kinetics

```{python}

scv.tl.velocity(adata, diff_kinetics=True)
scv.tl.velocity_graph(adata)
scv.pl.velocity_embedding(adata, dpi=120, arrow_size=2, arrow_length=2)
```
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.